{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T23:15:47.661838Z",
     "start_time": "2023-12-12T23:15:47.485428900Z"
    }
   },

   "execution_count": 6,
   "metadata": {},

   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",

    "review = pd.read_csv('../docs/oliveyoung_review_preprocessed.csv', encoding='UTF-8')\n",

    "review = review.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T23:15:49.182595900Z",
     "start_time": "2023-12-12T23:15:48.540914300Z"
    }
   },

   "execution_count": 22,
   "metadata": {},

   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(max_df=0.3,\n",
    "                        min_df=1,\n",
    "                        max_features=500)\n",
    "X = count.fit_transform(review['content'].values)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:17:08.074531100Z",
     "start_time": "2023-12-12T23:15:49.183592500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = 3, \n",
    "                                max_iter = 10,\n",
    "                                random_state=0,\n",
    "                                verbose=True,\n",
    "                               learning_offset = 7,\n",
    "                               learning_method='batch')\n",
    "lda_output = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T23:17:51.680328700Z",
     "start_time": "2023-12-12T23:17:51.664777600Z"
    }
   },

   "execution_count": 31,
   "metadata": {},

   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "구매 써다 보다 스킨 어서 자다 들다 이다 가격 사다 괜찮다 용량 느낌 쓸다 쓰기 보고 대용량 바르다 많다 닦토 그냥 다가 만족 촉촉 닦다 무난 추천 저렴 수분 선물 로션 려고 싶다 화장솜 아주 가성비 올리브영 주다 받다 할인 자극 난하 촉촉하다 제형 구입 처음 끄다 크다 진짜 한번 찾다 냄새 나오다 재구매 화장품 얼굴 브랜드 그렇다 독도 되어다 상품 라서 부담 하니 가다 면서 라인 넘다 오래 마음 그린 기도 매하 아내 여름 항상 기획 래서 가볍다 이지 작다 모르다 순하다 남자 매장 나다 정말 오다 믿다 사서 유명 흡수 계속 브링 패드 보습 차다 세트 남자친구 배송\n",
      "Topic 2:\n",
      "보습 제형 느낌 바르다 스킨 건조 자다 건성 들다 이다 보다 수분 크림 흡수 촉촉하다 어서 발라 타입 가볍다 써다 겨울 정말 에센스 지성 느끼다 추천 여름 수분감 아주 주다 면서 속건조 맞다 얼굴 그렇다 처럼 닦토 복합성 라인 앰플 진짜 채우다 케어 성분 마무리 해주 촉촉 기초 이나 되어다 수부지 완전 해지 래서 산뜻하다 거나 느껴지다 살짝 단계 화장솜 진정 로션 점성 트러블 쓰기 요즘 싶다 끈적임 나다 여러 미스트 한번 콧물 무향 만족 흐르다 많다 묽다 자극 처음 확실 흡토 구매 지다 그냥 화장 피지 괜찮다 민감성 오다 닥터 계절 레이어 당기다 세안 바꾸다 고요 민감 예민 늘다\n",
      "Topic 3:\n",
      "진정 효과 자극 트러블 보다 여드름 자다 이다 성분 들다 어서 구매 각질 닦토 추천 재구매 순하다 써다 화장솜 맞다 오다 정말 좁쌀 예민 진짜 해주 제거 되어다 얼굴 나다 민감 그렇다 피부결 바르다 느낌 민감성 라오 많다 모르다 다가 확실 거나 스킨팩 피지 도움 올라오다 적다 아주 어성초 붉다 받다 모공 면서 계속 만족 주다 지성 돼다 마스크 트리 찾다 느끼다 정리 싶다 매일 처럼 케어 제형 정돈 가라 지다 쓸다 크다 흡수 따갑다 묻히다 가격 보고 고민 넘다 앉다 패드 처음 완전 자극적 화장품 래서 수분 리뷰 의사 이나 어가 세안 닦다 저녁 자주 아침 추출 루지 관리\n"
     ]

    }
   ],
   "source": [
    "# LDA 결과 토픽 보기\n",
    "\n",
    "n_top_words = 100 # 토픽 관련 단어 20개 보기\n",

    "feature_names = count.get_feature_names()\n",

    "\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic %d:\" % (topic_idx + 1))\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()\\\n",
    "                        [:-n_top_words - 1:-1]]))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T23:17:08.096326400Z"
    }
   },

   "outputs": [],
   "source": [
    "###가성비: 가격 사다 괜찮다 용량 대용량 많다 닦토 만족 추천 저렴 가성비 할인 재구매 크다 부담 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T23:17:08.098649900Z"
    }
   },

   "outputs": [],
   "source": [
    "###보습: 보습 건조 건성 수분 흡수 촉촉하다 타입 겨울 지성 여름 수분감 속건조 복합성 채우다 촉촉 수부지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T23:17:08.100646500Z"
    }
   },

   "outputs": [],
   "source": [
    "###진정: 진정 자극 트러블 여드름 순하다 효과 좁쌀 예민 제거 나다 민감 민감성 피지 올라오다 어성초 붉다 티트리 가라 앉다 "
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'token2id'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyLDAvis\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgensim_models\u001B[39;00m\n\u001B[0;32m      4\u001B[0m pyLDAvis\u001B[38;5;241m.\u001B[39menable_notebook()\n\u001B[1;32m----> 5\u001B[0m vis \u001B[38;5;241m=\u001B[39m pyLDAvis\u001B[38;5;241m.\u001B[39mgensim_models\u001B[38;5;241m.\u001B[39mprepare(lda_output, X, count)\n\u001B[0;32m      6\u001B[0m pyLDAvis\u001B[38;5;241m.\u001B[39mdisplay(vis)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pyLDAvis\\gensim_models.py:122\u001B[0m, in \u001B[0;36mprepare\u001B[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprepare\u001B[39m(topic_model, corpus, dictionary, doc_topic_dist\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     78\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001B[39;00m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;124;03m    the data structures needed for the visualization.\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;124;03m    See `pyLDAvis.prepare` for **kwargs.\u001B[39;00m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     opts \u001B[38;5;241m=\u001B[39m fp\u001B[38;5;241m.\u001B[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001B[0;32m    123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pyLDAvis\u001B[38;5;241m.\u001B[39mprepare(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mopts)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pyLDAvis\\gensim_models.py:23\u001B[0m, in \u001B[0;36m_extract_data\u001B[1;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;66;03m# Need corpus to be a streaming gensim list corpus for len and inference functions below:\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     corpus \u001B[38;5;241m=\u001B[39m gensim\u001B[38;5;241m.\u001B[39mmatutils\u001B[38;5;241m.\u001B[39mSparse2Corpus(corpus_csc)\n\u001B[1;32m---> 23\u001B[0m vocab \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(dictionary\u001B[38;5;241m.\u001B[39mtoken2id\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# TODO: add the hyperparam to smooth it out? no beta in online LDA impl.. hmm..\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# for now, I'll just make sure we don't ever get zeros...\u001B[39;00m\n\u001B[0;32m     26\u001B[0m beta \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.01\u001B[39m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'CountVectorizer' object has no attribute 'token2id'"
     ]
    }
   ],
   "source": [
    "# 시각화\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda, X, count)\n",
    "pyLDAvis.display(vis)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:17:54.624696Z",
     "start_time": "2023-12-12T23:17:54.220799400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }

  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
