{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-08T09:39:18.596357400Z",
     "start_time": "2023-12-08T08:57:58.726552600Z"
    }
   },
   "outputs": [],
   "source": [
    "# 상품 리뷰 통계 정보 크롤링\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "REVIEW_REGEX_FORMAT = r'\\((\\d+|\\d+\\+?)\\)'\n",
    "MINIMUM_REVIEW_COUNT = 200\n",
    "\n",
    "class ProductReviewCrawler:\n",
    "    review_info_dictionary = {\n",
    "            'id': [],\n",
    "            'review_score': [],\n",
    "            'review_count' : [],\n",
    "            'skin_type1' : [],\n",
    "            'skin_type2' : [],\n",
    "            'skin_type3' : [],\n",
    "            'skin_effect1' : [],\n",
    "            'skin_effect2' : [],\n",
    "            'skin_effect3' : [],\n",
    "            'skin_stim1' : [],\n",
    "            'skin_stim2' : [],\n",
    "            'skin_stim3' : []\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.crawler = ProductDetailReviewInfoCrawler()\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        # 상품 일련번호(id)\n",
    "        # 사용자들의 리뷰 점수 평균과 수\n",
    "        # skin type (1: 건성, 2: 복합성, 3: 지성), skin_effect(1: 보습 효과, 2: 진정 효과, 3: 주름/미백 효과), skin_stim(1: 자극 없음, 2: 보통, 3: 자극 있음)\n",
    "        \n",
    "        review_info_dictionary = {\n",
    "            'id': [],\n",
    "            'review_score': [],\n",
    "            'review_count' : [],\n",
    "            'skin_type1' : [],\n",
    "            'skin_type2' : [],\n",
    "            'skin_type3' : [],\n",
    "            'skin_effect1' : [],\n",
    "            'skin_effect2' : [],\n",
    "            'skin_effect3' : [],\n",
    "            'skin_stim1' : [],\n",
    "            'skin_stim2' : [],\n",
    "            'skin_stim3' : []\n",
    "        }\n",
    "        \n",
    "        for page_idx in range(1, 15):\n",
    "            response = requests.get(\n",
    "                f'https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010013&fltDispCatNo=&prdSort=01&pageIdx={page_idx}&rowsPerPage=24&searchTypeSort=btn_list&plusButtonFlag=N&isLoginCnt=0&aShowCnt=0&bShowCnt=0&cShowCnt=0&trackingCd=Cat100000100010013_Small&amplitudePageGubun=&t_page=&t_click=&midCategory=%EC%8A%A4%ED%82%A8%2F%ED%86%A0%EB%84%88&smallCategory=%EC%A0%84%EC%B2%B4&checkBrnds=&lastChkBrnd=')\n",
    "            html = response.text\n",
    "\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            product_id_list = soup.select('li[criteo-goods]')\n",
    "            product_rating_list = soup.select(\"p.prd_point_area\")\n",
    "\n",
    "            for idx in range(len(product_id_list)):\n",
    "                review_count_string = product_rating_list[idx].text\n",
    "\n",
    "                match = re.search(REVIEW_REGEX_FORMAT, review_count_string)\n",
    "\n",
    "                if match:\n",
    "                    review_count = match.group(1)\n",
    "                    \n",
    "                    # 리뷰 수가 999+ 인 경우 처리\n",
    "                    if review_count[-1] == \"+\":\n",
    "                        review_count = review_count[:-1]\n",
    "\n",
    "                    if int(review_count) >= MINIMUM_REVIEW_COUNT:\n",
    "                        product_id = product_id_list[idx].attrs['criteo-goods']\n",
    "\n",
    "                        # A000000192697001 -> 실제 product id + 001을 붙여서 저장되어 있음\n",
    "                        product_id = product_id[:-3]\n",
    "                        review_info_dictionary = self.crawler.run(product_id, review_info_dictionary)\n",
    "                        \n",
    "        review_info_df = pd.DataFrame(review_info_dictionary)\n",
    "        \n",
    "        return review_info_df\n",
    "\n",
    "class ProductDetailReviewInfoCrawler:\n",
    "\n",
    "    def run(self, product_id, review_info_dictionary):\n",
    "        # 크롬 사용\n",
    "        driver = webdriver.Chrome()\n",
    "\n",
    "        url = f'https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do?goodsNo={product_id}&dispCatNo=100000100010013&trackingCd=Cat100000100010013_Small&t_page='\n",
    "        driver.get(url)\n",
    "\n",
    "        review_tab = driver.find_element(By.ID, 'reviewInfo')\n",
    "        review_tab.click()\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)  # 10 seconds timeout\n",
    "\n",
    "        # 대기 후 리뷰 탭이 나타날 때까지 wait\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'span.date')))\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        review_score = soup.select_one('p.num strong')\n",
    "        review_count = soup.select_one('p.total em')\n",
    "        skin_ratio_list = soup.select('em[data-value]')\n",
    "        \n",
    "        review_info_dictionary['id'].append(product_id)\n",
    "        review_info_dictionary['review_score'].append(review_score.text)\n",
    "        review_info_dictionary['review_count'].append(review_count.text)\n",
    "\n",
    "        for idx, skin_ratio in enumerate(skin_ratio_list):\n",
    "            value = int(skin_ratio['data-value'])\n",
    "            \n",
    "            if idx < 3:\n",
    "                # 첫 번째 3개의 값은 skin_type 관련 데이터\n",
    "                review_info_dictionary[f'skin_type{idx + 1}'].append(value)\n",
    "                \n",
    "            elif 3 <= idx < 6:\n",
    "                # 다음 3개의 값은 skin_effect 관련 데이터\n",
    "                review_info_dictionary[f'skin_effect{idx - 2}'].append(value)\n",
    "                \n",
    "            else:\n",
    "                # 마지막 3개의 값은 skin_stim 관련 데이터\n",
    "                review_info_dictionary[f'skin_stim{idx - 5}'].append(value)\n",
    "        \n",
    "        # 상품 상세페이지 종료\n",
    "        driver.quit()\n",
    "    \n",
    "        return review_info_dictionary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crawler = ProductReviewCrawler()\n",
    "    review_info_df = crawler.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from selenium.common import TimeoutException\n",
    "# 상품 리뷰 내용(댓글) 크롤링\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "REVIEW_REGEX_FORMAT = r'\\((\\d+|\\d+\\+?)\\)'\n",
    "MINIMUM_REVIEW_COUNT = 250\n",
    "\n",
    "class ProductReviewCrawler:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.crawler = ProductDetailReviewContentCrawler()\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        # 실제 댓글의 리뷰 내용을 담는다.\n",
    "        review_content_dictionary = {\n",
    "            'id': [],\n",
    "            'name': [],\n",
    "            'date': [],\n",
    "            'content': []\n",
    "        }\n",
    "        \n",
    "        for page_idx in range(1, 15):\n",
    "            response = requests.get(\n",
    "                f'https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010013&fltDispCatNo=&prdSort=01&pageIdx={page_idx}&rowsPerPage=24&searchTypeSort=btn_list&plusButtonFlag=N&isLoginCnt=0&aShowCnt=0&bShowCnt=0&cShowCnt=0&trackingCd=Cat100000100010013_Small&amplitudePageGubun=&t_page=&t_click=&midCategory=%EC%8A%A4%ED%82%A8%2F%ED%86%A0%EB%84%88&smallCategory=%EC%A0%84%EC%B2%B4&checkBrnds=&lastChkBrnd=')\n",
    "            html = response.text\n",
    "\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            product_id_list = soup.select('li[criteo-goods]')\n",
    "            product_rating_list = soup.select(\"p.prd_point_area\")\n",
    "\n",
    "            for idx in range(len(product_id_list)):\n",
    "                review_count_string = product_rating_list[idx].text\n",
    "\n",
    "                match = re.search(REVIEW_REGEX_FORMAT, review_count_string)\n",
    "\n",
    "                if match:\n",
    "                    review_count = match.group(1)\n",
    "\n",
    "                    if review_count[-1] == \"+\":\n",
    "                        review_count = review_count[:-1]\n",
    "\n",
    "                    if int(review_count) >= MINIMUM_REVIEW_COUNT:\n",
    "                        product_id = product_id_list[idx].attrs['criteo-goods']\n",
    "\n",
    "                        # A000000192697001 -> 실제 product id + 001을 붙여서 저장되어 있음\n",
    "                        product_id = product_id[:-3]\n",
    "                        \n",
    "                        if product_id != \"A000000007413\":\n",
    "                            review_content_dictionary = self.crawler.run(product_id, review_content_dictionary)\n",
    "\n",
    "        review_content_df = pd.DataFrame(review_content_dictionary)\n",
    "        return review_content_df\n",
    "\n",
    "class ProductDetailReviewContentCrawler:\n",
    "\n",
    "    def run(self, product_id, review_content_dictionary):\n",
    "        # 크롬 사용\n",
    "        driver = webdriver.Chrome()\n",
    "\n",
    "        url = f'https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do?goodsNo={product_id}&dispCatNo=100000100010013&trackingCd=Cat100000100010013_Small&t_page='\n",
    "        driver.get(url)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        product_name = soup.select_one('p.prd_name')\n",
    "\n",
    "        review_tab = driver.find_element(By.ID, 'reviewInfo')\n",
    "        review_tab.click()\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)  # 10 seconds timeout\n",
    "\n",
    "        # 대기 후 리뷰 탭이 나타날 때까지 wait\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'span.date')))\n",
    "        \n",
    "        # \"도움순\" 정렬 링크 클릭\n",
    "        try:\n",
    "            help_sort_link = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[data-sort-type-code='help']\")))\n",
    "            help_sort_link.click()\n",
    "        except TimeoutException:\n",
    "            return review_content_dictionary\n",
    "        \n",
    "        cnt = 0\n",
    "        page_index = 1\n",
    "        \n",
    "        while (cnt < 200):\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            # 리뷰 작성 날짜\n",
    "            review_dates = soup.select('span.date')\n",
    "            # 리뷰 내용\n",
    "            review_contents = soup.select('div.txt_inner')\n",
    "\n",
    "            # 필요한 데이터 저장\n",
    "            for idx in range(10):\n",
    "                if not product_name:\n",
    "                    return review_content_dictionary\n",
    "                else:\n",
    "                    review_content_dictionary['name'].append(product_name.text)                \n",
    "                \n",
    "                review_content_dictionary['id'].append(product_id)\n",
    "                \n",
    "                review_content_dictionary['date'].append(review_dates[idx].text)\n",
    "                \n",
    "                # 리뷰 텍스트가 존재하지 않는 경우도 있음. 빈 string값으로 채운다.\n",
    "                try:\n",
    "                    review_content_dictionary['content'].append(review_contents[idx].text)\n",
    "                except(IndexError):\n",
    "                    continue\n",
    "                \n",
    "                cnt += 1\n",
    "            wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'a[data-page-no=\"{page_index + 1}\"]')))\n",
    "            next_page_button = driver.find_element(By.CSS_SELECTOR, f'a[data-page-no=\"{page_index + 1}\"]')\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'span.date')))\n",
    "            \n",
    "            page_index += 1\n",
    "\n",
    "        # 상품 상세페이지 종료\n",
    "        driver.quit()\n",
    "\n",
    "        return review_content_dictionary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crawler = ProductReviewCrawler()\n",
    "    review_content_df = crawler.run()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T08:56:41.339030200Z",
     "start_time": "2023-12-08T07:40:07.702561600Z"
    }
   },
   "id": "537b1ecf9f94252a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "review_content_df.to_csv('review.csv', index=False, encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T10:36:14.293343500Z",
     "start_time": "2023-12-08T10:36:14.051557600Z"
    }
   },
   "id": "d19657a902f8936f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cd0015cd25f062d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
